import json
import os
import sys
from openai import OpenAI
from dotenv import load_dotenv

# [í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ]
load_dotenv()
API_KEY = os.getenv("OPENAI_API_KEY")

if not API_KEY:
    print("ğŸš¨ API Keyê°€ ì—†ìŠµë‹ˆë‹¤. .env íŒŒì¼ì˜ OPENAI_API_KEYë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”!")
    sys.exit(1)

client = OpenAI(api_key=API_KEY)

def augment_data(output_filename, augmentation_factor=5):
    """
    ì‘ì„± ì˜ë„: Golden Datasetì˜ ë¬¸ë§¥ì„ ìœ ì§€í•˜ë©° LLMì„ í†µí•´ í•™ìŠµ ë°ì´í„°ë¥¼ ì¦ê°•í•¨
    ì‘ìš©: 50ê°œì˜ ìƒ˜í”Œì„ ì‹œë“œë¡œ í•˜ì—¬ ì„¤ì •ëœ ë°°ìˆ˜ë§Œí¼ ë°ì´í„° ì–‘ì„ ëŠ˜ë¦¼
    """
    
    # 1. ê²½ë¡œ ì„¤ì • (ìŠ¤í¬ë¦½íŠ¸ ìœ„ì¹˜ ê¸°ì¤€)
    current_dir = os.path.dirname(os.path.abspath(__file__))
    input_file = os.path.join(current_dir, '..', 'dataset', 'goldendataset.json')
    output_file = os.path.join(current_dir, output_filename)

    if not os.path.exists(input_file):
        print(f"âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {input_file}")
        return

    with open(input_file, 'r', encoding='utf-8') as f:
        original_data = json.load(f)

    augmented_results = []

    for item in original_data:
        print(f"ğŸ”„ ì¦ê°• ì¤‘: {item['id']} ({item['metadata'].get('dataset_type', 'N/A')})")
        
        # 2. GPTì—ê²Œ ì „ë‹¬í•  í”„ë¡¬í”„íŠ¸ ì„¤ê³„ (JSON í‚¤ê°’ ëª…ì‹œ)
        prompt = f"""
        ë‹¹ì‹ ì€ B2G ì…ì°° ì»¨ì„¤íŒ… ë°ì´í„° ì—”ì§€ë‹ˆì–´ì…ë‹ˆë‹¤. 
        ì•„ë˜ ì œê³µëœ 'ì›ë³¸ ë°ì´í„°'ì˜ [ì»¨í…ìŠ¤íŠ¸]ë¥¼ ë°”íƒ•ìœ¼ë¡œ, ìƒˆë¡œìš´ [ì§ˆë¬¸]ê³¼ [ë‹µë³€] ìŒì„ {augmentation_factor}ê°œ ìƒì„±í•˜ì„¸ìš”.
        
        [ì›ë³¸ ì»¨í…ìŠ¤íŠ¸]:
        {item['contexts']}
        
        [ê°€ì´ë“œë¼ì¸]:
        1. ì§ˆë¬¸ì˜ í˜•ì‹ì„ ë‹¤ì–‘í•˜ê²Œ í•˜ì„¸ìš” (ìš”ì•½ ìš”ì²­, íŠ¹ì • ìˆ˜ì¹˜ ì¶”ì¶œ, ë¹„êµ ë¶„ì„ ë“±).
        2. ë‹µë³€ì€ ë°˜ë“œì‹œ ì œê³µëœ ì»¨í…ìŠ¤íŠ¸ì— ê·¼ê±°í•´ì•¼ í•©ë‹ˆë‹¤.
        3. 'samples'ë¼ëŠ” í‚¤ë¥¼ ê°€ì§„ JSON ê°ì²´ ë‚´ì— ë¦¬ìŠ¤íŠ¸ í˜•ì‹ìœ¼ë¡œ ì¶œë ¥í•˜ì„¸ìš”.
        4. í˜•ì‹: {{"samples": [{{"question": "...", "answer": "...", "ground_truth": "..."}}]}}
        """

        try:
            response = client.chat.completions.create(
                model="gpt-5",
                messages=[{"role": "user", "content": prompt}],
                response_format={ "type": "json_object" }
            )

            # 3. ìƒì„±ëœ ë°ì´í„° íŒŒì‹±
            response_data = json.loads(response.choices[0].message.content)
            new_samples = response_data.get("samples", [])

            # 4. ID ë¶€ì—¬ ë° ë©”íƒ€ë°ì´í„° ìƒì† (í•™ìŠµ ì‹œ ë°ì´í„° ì¶”ì ì„ ìœ„í•´ í•„ìˆ˜)
            for i, sample in enumerate(new_samples):
                sample["id"] = f"aug_{item['id']}_{i+1}"
                sample["contexts"] = item["contexts"] # ì›ë³¸ ì»¨í…ìŠ¤íŠ¸ ìƒì†
                sample["metadata"] = item["metadata"] # ë©”íƒ€ë°ì´í„° ìƒì†
                augmented_results.append(sample)
                
        except Exception as e:
            print(f"âš ï¸ {item['id']} ì¦ê°• ì¤‘ ì—ëŸ¬ ë°œìƒ: {e}")

    # 5. ìµœì¢… ê²°ê³¼ ì €ì¥ (JSONL ëŒ€ì‹  JSONìœ¼ë¡œ ë¨¼ì € ì €ì¥í•˜ì—¬ ê°€ë…ì„± í™•ë³´)
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(augmented_results, f, ensure_ascii=False, indent=2)
    
    print(f"\nâœ… ì¦ê°• ì™„ë£Œ! ì´ {len(augmented_results)}ê°œì˜ ë°ì´í„°ê°€ {output_file}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

# ì‹¤í–‰ (ì¦ê°• ë°°ìˆ˜ëŠ” í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•´ 3 ì •ë„ë¡œ ì‹œì‘í•˜ëŠ” ê²ƒì„ ì¶”ì²œí•©ë‹ˆë‹¤)
if __name__ == "__main__":
    augment_data('augmented_dataset2.json', augmentation_factor=6)