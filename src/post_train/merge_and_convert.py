import json
import os

#==============================================
# í”„ë¡œê·¸ë¨ëª…: merge_and_convert.py
# í´ë”ìœ„ì¹˜: src/post_train/merge_and_convert.py
# í”„ë¡œê·¸ë¨ ì„¤ëª…: í•™ìŠµ ë°ì´í„°ì…‹ë“¤ì„ ëª¨ì•„ì„œ ë³‘í•©í•˜ê³  í•™ìŠµ ê·œê²©ìœ¼ë¡œ ë³€í™˜í•˜ëŠ” í”„ë¡œê·¸ë¨
# ì‘ì„±ì´ë ¥: 25.12.22 í•œìƒì¤€ ìµœì´ˆ ì‘ì„±
#===============================================

# ì‘ì„± ì˜ë„: í©ì–´ì ¸ ìˆëŠ” ì¦ê°• ë°ì´í„°ë“¤ì„ í•˜ë‚˜ë¡œ í†µí•©í•˜ê³  í•™ìŠµ ê·œê²©(JSONL)ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
def merge_to_jsonl(file_list, output_filename):
    total_samples = 0
    current_dir = os.path.dirname(os.path.abspath(__file__))
    output_path = os.path.join(current_dir, output_filename)

    with open(output_path, 'w', encoding='utf-8') as f_out:
        for file_name in file_list:
            input_path = os.path.join(current_dir, file_name)
            
            if not os.path.exists(input_path):
                print(f"âš ï¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {file_name}")
                continue

            with open(input_path, 'r', encoding='utf-8') as f_in:
                data = json.load(f_in)
                for item in data:
                    # JSON ê°ì²´ë¥¼ í•œ ì¤„ì˜ ë¬¸ìì—´ë¡œ ë³€í™˜í•˜ì—¬ ì €ì¥
                    f_out.write(json.dumps(item, ensure_ascii=False) + '\n')
                    total_samples += 1
            
            print(f"ğŸ“– {file_name} ì²˜ë¦¬ ì™„ë£Œ...")

    print(f"âœ… í†µí•© ì™„ë£Œ! ì´ {total_samples}ê°œì˜ ë°ì´í„°ê°€ {output_path}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

# ì‹¤í–‰: ë‘ íŒŒì¼ì„ í•©ì³ì„œ train_sft.jsonl ìƒì„±
if __name__ == "__main__":
    files_to_merge = ['augmented_dataset.json', 'augmented_dataset2.json']
    merge_to_jsonl(files_to_merge, 'train_sft.jsonl')